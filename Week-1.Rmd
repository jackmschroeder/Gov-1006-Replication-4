---
title: 'Replication #4'
author: "Jack Schroeder"
date: "3/12/2019"
output:
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# I'm still not entirely sure what the rm function is doing here
# (I know it removes objects), but I'm keeping it until I know
# for sure I don't need it.

rm(list = ls())

# I also call in tidyverse in case I need it later on.

library(tidyverse)
library(simpleboot)
library(boot)
library(Zelig)
library(stargazer)

# I also load in the csv files Enos calls for. I make sure to turn
# equals signs into <-. I keep the reads in as read.csv as to not
# mess too much with the data.

wtreat <- read.csv('enos_files/white.treat.effect.mean.boot.csv') 
wtreat.lower <- read.csv('enos_files/white.treat.effect.conf.boot.lower.csv') 
wtreat.upper <- read.csv('enos_files/white.treat.effect.conf.boot.upper.csv') 
Nwtreat <- read.csv('enos_files/white.treat.N.csv')
btreat <- read.csv('enos_files/black.treat.effect.mean.boot.csv') 
btreat.lower <- read.csv('enos_files/black.treat.effect.conf.boot.lower.csv') 
btreat.upper <- read.csv('enos_files/black.treat.effect.conf.boot.upper.csv') 
Nbtreat <- read.csv('enos_files/black.treat.N.csv')
distdat <- read.csv('enos_files/predicted.results.distance.vary.context.csv')
areadat <- read.csv('enos_files/predicted.results.area.vary.context.csv')
groups <- read.csv('enos_files/par.trends.csv')
dists <- read.csv('enos_files/distance.vote.differences.csv')
demos <- read.csv('enos_files/demolished.vote.differences.csv')

# This next csv is needed for the data work of the second week:

data <- read.csv("enos_files/data.turnout.csv")

# There are other csvs read in, but they are all in for loops.
# Since Enos gives them similar names, I don't want to mess with
# them yet.

# I like Enos' for loop that turns the tibbles into matrices (which I
# guess for him are easier to use). I'll keep it in for now.

for(i in 1:nrow(wtreat)){
	use.wtreat <- as.matrix(wtreat[i,])
	use.wlower <- as.matrix(wtreat.lower[i,])
	use.wupper <- as.matrix(wtreat.upper[i,])
	use.Nwtreat <- as.matrix(Nwtreat[i,])
	use.btreat <- as.matrix(btreat[i,])
	use.blower <- as.matrix(btreat.lower[i,])
	use.bupper <- as.matrix(btreat.upper[i,])
	use.Nbtreat <- as.matrix(Nbtreat[i,])
}

```

## Abstract
I replicate Enos' "What the Demolition of Public Housing Teaches Us about the Impact of Racial Threat on Political Behavior" using the author's replication data from the Harvard Dataverse (@data). @article's figures replicate, but his table cannot be recreated since the necessary dataset is not included in the Dataverse.  

```{r master parameters, echo=FALSE}

# Enos sets certain parameters for the graphics that follow.
# I keep them as they are.

# These are setting limits on the axes and setting other values
# for the x and y axes.

ylims = c(-.35,.1)
ylims.2 = c(-.45,.1)
xlims = c(.5,11)
dists = seq(from = 1000, to = 100, by = -100)
xs = seq(1:length(dists))
ys = seq(from = -.35, to = .1, by = .05)
ys.lab = c('-0.35','-0.30', '-0.25','-0.20','-0.15','-0.10','-0.05','0.00','0.05','0.10')
ys.2 = seq(from = -.45, to = .1, by = .05)
ys.lab.2 = c('-0.45','-0.40','-0.35','-0.30', '-0.25','-0.20','-0.15','-0.10','-0.05','0.00','0.05','0.10')

# This code helps out when text, lines, and points are added to
# graphs.

offsets  =  .15
text.offsets = .025
cex.axis = .9
cex.N = .7
top.text.adj = c(1.3,1.3)
bottom.text.adj = c(-.15,-.85)
point.size = 2
line.offset = .0175

# Enos also sets this code aside for when he has to use letters.

use.letters <- c('a','b','c','d','e','f','skip','g','h')

```

## Replication

### Figure 1. Treatment Effects

```{r figure 1, echo=FALSE}

# The general code to create the graph. He first sets parameters and 
# then creates the actual graph using a matrix he created above.

# He also relies on some of his general parameters (ylims, xlims).

	par(las = 1)
	par(mar = c(5.1, 4.1, .5, .5))
	plot(xs, use.wtreat,
		ylim = ylims,
		xlim = xlims,
		type = 'n',
		ylab = 'Treatment Effect',
		xlab = 'Treated Group Distance from Projects',
		xaxt = 'n',
		yaxt = 'n.csv')
	abline(h = 0, lty = 2)
	
# His justification for having this code above the point creation is
# that he wants the lines drawn and the points put on top. There has
# to be a better way to do this (especially when he creates spacing 
# specifically for the N values). He offsets the black and white voter
# data so they do not appear on top of one another.
	
	segments(x0= xs[1:2]+offsets, x1 = xs[1:2]+offsets,
		y0 = use.btreat[,1:2], y1 =	use.blower[,1:2])
	segments(x0= xs[1:2]+offsets, x1 = xs[1:2]+offsets,
		y0 = use.btreat[,1:2] + line.offset, 	y1 =	use.bupper[,1:2])
	segments(x0= xs[3:10]+offsets, x1 = xs[3:10]+offsets,
		y0 = use.blower[,3:10], 	y1 =	use.bupper[,3:10])
		
# Enos creates the top and bottom lines.
	
	segments(x0= xs-offsets, x1 = xs-offsets,
		y0 = use.wtreat - line.offset, 	y1 =	use.wlower)
	segments(x0= xs-offsets, x1 = xs-offsets,
		y0 = use.wtreat, 	y1 =	use.wupper)

  
# Enos uses this code to make the points on the graph and display the
# proper N values. It's worth noting that this is a cumulative graph.

	points(xs-offsets, use.wtreat,
	       cex = point.size,
	       pch = 21, 
	       bg = 'white',
	       col = 'black')
	text(xs-offsets,use.wtreat,
	     paste('(',use.Nwtreat,')',sep = ''),
	     cex = cex.N,
	     pos = 1
	    )
	
	points(xs+offsets, use.btreat,
	       pch = 16,
	       cex = point.size)
	text(xs+offsets,use.btreat,
	     paste('(',use.Nbtreat,')',sep = ''),
	     cex = cex.N,
	     pos = 3
	    )

# Now Enos works on formatting the axes.
	
	axis(side = 1,
		at = xs,
		label = seq(100,1000,100),
		cex.axis = cex.axis
		)
	axis(side = 2,
		at = ys,
		label = ys.lab,
		cex.axis = cex.axis
		)

```

Note: Difference-in-differences results for treatment groups defined by increasing distance from the demolished projects. Differences are for the mean turnout in 2004 minus the mean turnout in 2000 for the treatment group minus the same difference for the control group. White circles represent the mean effect on white voters; black circles represent the mean effect on black voters. The N in each treatment group is in parentheses next to the mean effect. Vertical lines represent the 95% confidence intervals generated by bootstrapped standard errors of the difference between treatment and control.

### Figure 2. Treatment Effects Using Matched White Voters Near Nondemolished Projects for Control Group

#### and  

### Figure 3. Treatment Effects Using Matched Black Control Group and Controlling for Homeownership

```{r figures 2 and 3, echo=FALSE}

# Enos uses a for loop to create figure 2. Thankfully, Helen lets us know that
# the for loop doesn't need every if statement, only the ones looking at the
# white.demo.main and blackmain csvs.

##this cycles thorugh a bunch of dataframes, each of which is needed for a different graph
for(figure in c('white.demo.main','blackmain')){

	if(figure == 'white.demo.main'){
		treat <- read.csv('enos_files/white.match.nondemolished.csv')
		diffs <- read.csv('enos_files/white.match.nondemolished.diffs.csv')
		fig.nums <- c('2','A5')
		pchs <- c(17,22)
		}

	if(figure == 'blackmain'){
		treat <- read.csv('enos_files/white.match.black.property.csv')
		diffs <- read.csv('enos_files/white.match.black.diffs.property.csv')
		fig.nums <- c('3','A12')
		pchs <- c(17,21)			
		}

# From there, it's a question of setting up the graph using these new parameters below:
  
			use.ylims <- ylims
			use.ys.lab <- ys.lab
			use.ys <- ys
			use.treat <- treat$coefficient			
			clower <- use.treat-(1.96*treat$stdev)
			cupper <- use.treat+(1.96*treat$stdev)
			use.N.treat <- treat$N.treatment + treat$N.control

# Then the plot is created!
			
			par(las = 1)
			par(mar = c(5.1, 4.1, .5, .5))
			plot(xs, use.treat,
				ylim = use.ylims,
				xlim = xlims,
				type = 'n',
				ylab = 'Treatment Effect',
				xlab = 'Treated Group Distance from Projects',
				xaxt = 'n',
				yaxt = 'n')
			abline(h = 0, lty = 2)
			
# These segments and points create the treatment effect and their intervals (along with N values)
			
			segments(x0=xs,x1=xs,
						y0= use.treat+line.offset,y1=cupper)
			segments(x0=xs,x1=xs,
						y0= use.treat,y1=clower)
			points(xs, use.treat, 
				pch = pchs[i], 
				cex = point.size,
					bg = 'white',
       			col = 'black')
			text(xs,use.treat,
			     paste('(',use.N.treat,')',sep = ''),
			     cex = cex.N,
			     pos = 3
			  )

# Then Enos sets the axes.
			
			axis(side = 1,
					at = xs,
					label = seq(100,1000,100),
					cex.axis = cex.axis
					)
			axis(side = 2,
					at = use.ys,
					label = use.ys.lab,
					cex.axis = cex.axis
					)
}
```

Note on both figures: Coefficients on treatment as defined by increasing distance from the demolished projects from OLS regressions on change in turnout from 2000 to 2004 (triangles). N for the regression using matched groups is next to the point representing the coefficient. The treatment group in Figure 2 treatment group is matched to a control group of white voters living near projects that were not demolished, using nearest neighbor matching. The treatment group in Figure 3 is matched to a black control group of the same N using the same matching system, including variables on homeownership and home value. Regressions include variables used in matching as controls. Vertical lines represent the 95% confidence intervals generated by bootstrapped standard errors on the treatment coefficient.

### Figure 4. Effects of Distance and Size of Projects

```{r figure 4, echo=FALSE}

# These graphs have new limits for the y-axis, set here:

ylims.predict <- c(.6,.75)

# The for loop will cycle through distdat and areadat, which were read in at the top.

datas <- list(distdat,areadat)

# There are some new parameters here for graphmaking:

xs <- list(seq(from = 10, to = 2000, by = 10), seq(from = 45000, to = 1004000, by = 4800)/1000)
use.letters <- c('a','b')
xlabs <- c('Distance from Project','Percent of Local Black Population in Demolished Project')
ylabs <- c(expression(Pr(vote[2004])),'')
vlines <- list(seq(from = 0, to = 2000, by = 200),seq(from = 0, to = 1000, by = 100))
axis.labs <- list(as.character(seq(from = 0, to = 2000, by = 200)),
	as.character(c('0','10%','20%','30%','40%','50%','60%','70%','80%','90%','100%')))

# Enos does yet another for loop to create his figure.

for(i in 1:2){
	colnames(datas[[i]]) = c("mean","sd","50%","2.5%","97.5%") ##saving renames columns, so name back

		par(las = 1)
		par(mar = c(5.1, 4.1, .5, .5))
		plot(xs[[i]],datas[[i]][,'mean'],
			type = 'l',
			xlab = xlabs[i],
			ylab = ylabs[i],
			ylim = ylims.predict,
			xaxt = 'n',
			cex.axis = cex.axis,
			lwd = 4
		)

# These lines of code add lines to the plot.
		
	abline(h = seq(from = min(ylims.predict), to = max(ylims.predict), by = .025),
	       lty = 2,
	       col = 'gray',
	       lwd = 1)
	abline(v = vlines[[i]], 
	       lty = 2,
	       col = 'gray',
	       lwd = 1)
	lines(xs[[i]],datas[[i]][,'2.5%'],
			lty = 3,
			lwd = 2.5)
	lines(xs[[i]],datas[[i]][,'97.5%'],
			lty = 3,
			lwd = 2.5)
	axis(side = 1, 
		at = vlines[[i]], 
		labels = axis.labs[[i]],
		cex.axis = .9)
		
}

```

Note: Predicted effects generated from $vote2004 = 􏰀0 + 􏰀1(log(distance)) + 􏰀2(log(localpercent)) + vote2000$, with white voters. Figure 4(a) is the predicted probability that a person who voted in 2000 will vote in 2004 with increasing distance, while holding size at its mean. Figure 4(b) is the predicted probability that a person who voted in 2000 will vote in 2004, with increasing outgroup population size, with distance = 100. Dotted lines represent 95% confidence intervals generated by bootstrapped standard errors.  

### Figure 5. Difference in Republican Vote for Matched Precincts

```{r figure 5, echo=FALSE}

# Enos creates pres.elections and obama.elections to allow him to look at
# election stats from the presidential elections (looking at Republicans
# like Dole, Bush, and McCain) and Obama's elections (his Senate primary,
# his Senate election against Keyes, and his presidential primary).

pres.elections  <- c('dole_pct_ei','bush2000_pct_ei','bush2004_pct_ei','mccain_pct_ei')
obama.elections <- c('obama_sen_primary_pct_ei','keyes_pct_ei','obama_pres_primary_pct_ei')

# Also read in the csv files.

dists <- read.csv('enos_files/distance.vote.differences.csv')
demos <- read.csv('enos_files/demolished.vote.differences.csv')


graphs <- c('5a','5b')

for(i in graphs){

	if(i == '5a'){dat = dists}
	else{dat = demos}
  
  # Enos sets new limits for the plot:
  xlims = c(.75,4.25)
	ylims = c(-.1,.2)

  # I calculate the difference in Republican vote by looking at the vote for
	# Keyes (Obama's opponent).
	
	dat[dat$election == 'keyes_pct_ei','x.mean'] = 1 - dat[dat$election == 'keyes_pct_ei','x.mean']
	dat[dat$election == 'keyes_pct_ei','y.mean'] = 1 - dat[dat$election == 'keyes_pct_ei','y.mean']
	dat[dat$election == 'keyes_pct_ei','diff'] =dat[dat$election == 'keyes_pct_ei','y.mean'] - dat[dat$election == 'keyes_pct_ei','x.mean']

	# This graph has new parameters.
	par(las = 1, mar = c(10, 4, 5, .1), mai = c(1.22,0.82,0.82,0.1))
	
	# Then I construct the figure.
	plot(seq(1:4),
	     rep(1,4),
	     ylim = ylims,
	     xlim = xlims,
	     type = 'n',
	     xaxt = 'n',
	     yaxt = 'n',
	     xlab = 'Election\n',
	     ylab = 'Treatment Effect')
	
	title(main = ifelse(i == '5b','Figure 5b','Figure 5a'))
	
	abline(h=0, lty = 2)
	
	# Enos does the same offsetting to make the points look nicer
	points(seq(1:4)-offsets,
	       dat[dat$group == 'white'&dat$election %in% pres.elections,'diff'],
	       pch = 21,
	       bg = 'white', col = 'black',
	       cex = 2)
	
	# Enos constructs and plots the confidence intervals
	segments(x0= seq(1:4)-offsets,
	         x1 = seq(1:4)-offsets,
	         y0 = dat[dat$group == 'white'&dat$election %in% 
	                    pres.elections,'diff']-(1.96*dat[dat$group == 'white'&dat$election %in% pres.elections,'sd']),

	         y1 =	dat[dat$group == 'white'&dat$election %in% 
	                    pres.elections,'diff']+(1.96*dat[dat$group == 'white'&dat$election %in% pres.elections,'sd']))
	segments(x0= seq(1:4)+offsets, x1 = seq(1:4)+offsets,
	         y0 = dat[dat$group == 'black'&dat$election %in% 
	                    pres.elections,'diff']-(1.96*dat[dat$group == 'black'&dat$election %in% pres.elections,'sd']),
	         y1 =	dat[dat$group == 'black'&dat$election %in% 
	                    pres.elections,'diff']+(1.96*dat[dat$group == 'black'&dat$election %in% pres.elections,'sd']))
			
	# Enos plots the actual points on the graph
	
	points(seq(1:4)+offsets,
	       dat[dat$group == 'black'&dat$election %in% pres.elections,'diff'],
	       pch = 16, cex = 2)
			
	# Then Enos labels the axes
	
	axis(side = 1, at = seq(1:4),
	     c('1996','2000','2004','2008'),
	     tick = F,
	     cex.axis = cex.axis)
	axis(side = 2,
	     at = seq(from = -.1, to = .3, by = .05),
	     label = c('-0.10','-0.05','0.00','0.05','0.10','0.15','0.20','0.25','0.30'),
	     cex.axis = cex.axis)
}
```

Note: Figure 5(a) shows differences in weighted mean Republican vote for precincts with $d ≤ 1,000$ and matched precincts with $d > 1,000$ for white voters (white circles) and black voters (black circles). Figure 5(b) shows differences in weighted mean Republican vote for white voters and black voters matched with precincts with $d ≤ 1,000$ from nondemolished projects.

### Figure 6. Difference in Obama Vote for Matched Precincts

```{r figure 6, echo=FALSE}

# In order to get figures 5 and 6 to replicate in separate code chunks,
# I based my analysis on Enxhi's work. However, as I learned over the
# next several hours, small semantic changes like leaving a line of 
# blank space after a comment prevented the entire project from
# knitting. I still don't really know why it happens (might
# have something to do with tabs in on Enos' code?), but given
# that I know it does, I'm using the formatting that allows me
# to knit.

# Enos reframes dat.

dat <- demos

# He then sets plot limits
xlims = c(.75,3.25)
ylims = c(-.1,.25)

# Then he calculates the difference in party vote for the Obama Senate general
dat[dat$election == 'keyes_pct_ei','x.mean'] = 1 - dat[dat$election == 'keyes_pct_ei','x.mean']
dat[dat$election == 'keyes_pct_ei','y.mean'] = 1 - dat[dat$election == 'keyes_pct_ei','y.mean']
dat[dat$election == 'keyes_pct_ei','diff'] =dat[dat$election == 'keyes_pct_ei','y.mean'] - dat[dat$election == 'keyes_pct_ei','x.mean']

# He creates new parameters for the plot
par(las = 1, mar = c(5.1, 4.1, .5, 1.5))

# And then Enos constructs the plot
plot(seq(1:4),
     rep(1,4),
     ylim = ylims,
     xlim = xlims,
     type = 'n',
     xaxt = 'n',
     yaxt = 'n',
     xlab = 'Election',
     ylab = 'Treatment Effect')
abline(h=0, lty = 2)

# Enos constructs the confidence intervals for white voters
segments(x0 = seq(1:3)-offsets,
         x1 = seq(1:3)-offsets,
         y0 = dat[dat$group == 'white'&dat$election %in% 
                    obama.elections,'diff']-(1.96*dat[dat$group == 'white'&dat$election %in% obama.elections,'sd']),
         y1 =	dat[dat$group == 'white'&dat$election %in% 
				           obama.elections,'diff']+(1.96*dat[dat$group == 'white'&dat$election %in% obama.elections,'sd']))
# Enos constructs the confidence intervals for black voters
segments(x0= seq(1:3)+offsets,
         x1 = seq(1:3)+offsets,
         y0 = dat[dat$group == 'black'&dat$election %in% 
                    obama.elections,'diff']-(1.96*dat[dat$group == 'black'&dat$election %in% obama.elections,'sd']),
         y1 =	dat[dat$group == 'black'&dat$election %in% 
                    obama.elections,'diff']+(1.96*dat[dat$group == 'black'&dat$election %in% obama.elections,'sd']))
  			
# Enos creates the white points
points(seq(1:3)-offsets,
       dat[dat$group == 'white'&dat$election %in% obama.elections,'diff'],
       pch = 21,
       bg = 'white', col = 'black',
       cex = 2)

# He then creates the black points on the figure
points(seq(1:3)+offsets,
       dat[dat$group == 'black'&dat$election %in% obama.elections,'diff'],
       pch = 16, cex = 2)

# Finally, he labels the axes		
axis(side = 1, at = seq(1:3),
     c('2004 \n Senate Primary','2004 \n Senate General','2008 \n President Primary'),
     tick = F,
     cex.axis = cex.axis)
axis(side = 2,
     at = seq(from = -.1, to = .3, by = .05),
     label = c('-0.10','-0.05','0.00','0.05','0.10','0.15','0.20','0.25','0.30'),
     cex.axis = cex.axis)
```

Note:  Note: Differences in weighted mean Obama vote for precincts with $d ≤ 1,000$ for de- molished projects and matched precincts with $d ≤ 1,000$ for nondemolished projects for white voters (white circles) and black voters (black circles).

```{r turnout, echo=FALSE, cache=TRUE, warning=FALSE, error=FALSE, message=FALSE, results='hide'}

# I then look at Enos' data creation code (for which Gabe's code was super helpful).
# Our focus is on turnout.r, which reads in the csv file on turnout (which I assign
# above as data).

# Enos changes some variables into dates and factors.

data$reg <- as.Date(data$reg)
data$p <- as.factor(data$p)
data$s <- as.factor(data$s)

# Enos also sets distances as a maximum of 1000 (although he says 1k 
# defines a neighborhood).

dists <- seq(from = 100, to = 1000, by = 100)

# He also stores a few percentages (one of which ends up being used
# to determine whether a name is white enough for treatment [97.5%]).

namepcts <- c(seq(from = .91, to = .96, by = .01),.975,.99,1)

# He then creates matrices for "strong results".

res.mat <- matrix(nrow=length(namepcts),ncol=length(dists))

# Enos assigns these as part of the difference-in-difference analysis.

white.treat.N <- res.mat
white.treat.effect.mean.boot <- res.mat
white.treat.effect.conf.boot.lower <- res.mat
white.treat.effect.conf.boot.upper <- res.mat

black.treat.N <- res.mat
black.treat.effect.mean.boot <- res.mat
black.treat.effect.conf.boot.lower <- res.mat
black.treat.effect.conf.boot.upper <- res.mat

# Enos cuts the registration date at this time since the registration
# cutoff for IL is 27 days before the election.

use.data <- data[data$reg <"2000-10-10" & is.na(data$reg) == F, ]

# Loop through definitions of white and distances and estimate at each combination.

for(j in 1:length(namepcts)){
  
# Define a treatment and control group for each name percent
  
	useW <- use.data[use.data$whitename >= namepcts[j],]
   useB <- use.data[use.data$blackname >= namepcts[j],]
  
    for(h in 1:length(dists)){
      	Wtreat <- useW[useW$demo.distance <= dists[h],]
      	Btreat <- useB[useB$demo.distance <= dists[h],]
      	Wcont <- useW[useW$demo.distance > dists[h],]
      	Bcont <- useB[useB$demo.distance > dists[h],]     		
      	white.treat.N[j,h] <- nrow(Wtreat)
      	black.treat.N[j,h] <- nrow(Btreat)
      	
# Enos wants to bootstrap the standard errors after the t test of difference
# of means for white and black subjects. I take it out to help knit faster.

		if(white.treat.N[j,h] > 0){
			white.boot <- two.boot((Wtreat$vote2004-Wtreat$vote2000),(Wcont$vote2004-Wcont$vote2000), mean, R = 2, na.rm=T)
			white.treat.effect.mean.boot[j,h] <- white.boot$t0
			white.boot.ci <- boot.ci(white.boot, type = 'basic')
			white.treat.effect.conf.boot.lower[j,h] <- white.boot.ci$basic[4]
			white.treat.effect.conf.boot.upper[j,h] <- white.boot.ci$basic[5]
		      		}

		if(black.treat.N[j,h] > 0){
			black.boot <- two.boot((Btreat$vote2004-Btreat$vote2000),(Bcont$vote2004-Bcont$vote2000),mean, R = 2, na.rm=T)
			black.treat.effect.mean.boot[j,h] <- black.boot$t0
			black.boot.ci <- boot.ci(black.boot, type = 'basic')
			black.treat.effect.conf.boot.lower[j,h] <- black.boot.ci$basic[4]
			black.treat.effect.conf.boot.upper[j,h] <- black.boot.ci$basic[5]
			 }
		}
	}

```


```{r simulation, echo=FALSE, cache=TRUE, warning=FALSE, error=FALSE, message=FALSE, results='hide'}

# Enos creates the predicted effects for distance and context changes.

# He subsets the data to eliminate NA values and find registered (white) voters.

white.data <- data[as.Date(data$reg) < "2000-10-10" & is.na(data$reg) == F, ]

# Enos only selects white subjects whose names have < 97.5% change of being white
# (per his method described at length in another of his papers).

white.data <- white.data[white.data$whitename >= .975,]

# This is the data he uses, so he assigns it to usedata.

usedata <- white.data

# He increases the distances here to 2000 (as opposed to 2000 before).

distances <- seq(from = 10, to = 2000, by = 10)

# He also sets areas for estimation below.

areas <- seq(from = 0, to = 1, length.out = length(distances))
			      
# Enos describes this as a storing bin.

outmat.s <- matrix(ncol = 5, nrow = 0)
outmat.d <- matrix(ncol = 5, nrow = 0)

# He creates a model that will be used in table 1.

model1 <- zelig(vote2004 ~ log(demo.distance) + log(context_black) + vote2000, data = usedata, model = 'ls', cite = F)

# He then simulates this regression across different variable
# values.

for(i in seq(1:length(distances))){
	print(i)
	use.distance = distances[i]
	out.d.1 = setx(model1,
		vote2000 = 1,
		demo.distance = use.distance)

	out.d.sims = sim(model1,
		x = out.d.1)
	
	use.area = areas[i]	
	out.s.1 = setx(model1,
		vote2000 = 1,
		demo.distance = 100,
		context_black = use.area)

	out.s.sims = sim(model1,
		x = out.s.1)

	outstats.d = summary(out.d.sims)$stats[[1]]
	outstats.s = summary(out.s.sims)$stats[[1]]
	
	outmat.d = rbind(outmat.d,outstats.d)
	outmat.s = rbind(outmat.s,outstats.s)
	}

# He finally stores the results for future use. We don't
# have to worry about these for now.

predicted.results.distance.vary.context <- outmat.d
predicted.results.area.vary.context <- outmat.s
model1.predict <- model1

```

### Table 1. Regression of Turnout on Distance and Population Size

```{r table1, echo=FALSE, results='asis'}

# Redefine model1 as an lm model so it works nicely with Stargazer.

model1 <- lm(vote2004 ~ log(demo.distance) + log(context_black) + vote2000, data = usedata)

# I use Stargazer to create a nice-looking table of model1.

stargazer(model1, header = FALSE, type = "html")
```

## References

Enos, R. (2015). What the demolition of public hosuing teaches us about the imapct of racial threat on political behavior. *American Journal of Political Science 0*(0). pp. 1-20.

Enos, R. (2015). Replication data for: What the demolition of public housing teaches us about the impact of racial threat on political behavior. *Harvard Dataverse*. Reached at dataverse.harvard.edu
